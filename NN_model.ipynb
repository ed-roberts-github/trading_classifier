{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classifier\n",
    "\n",
    "In this notebook I explore building a neural netwrok classifier from lagged returns data. As with the SVM, this model is fundamentally flawed due to the efficient markets hypothesis, but again this provides good practice for building and backtesting models.\n",
    "\n",
    "I use PyTorch and Lightning here. This is obviously overkill for such a simple NN classifier however, it is once again a good learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_l1, hidden_l2):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l1, hidden_l2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l2, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitClassifier(L.LightningModule):\n",
    "    def __init__(self, Classifier, learning_rate):\n",
    "        super().__init__()\n",
    "        self.Classifier = Classifier\n",
    "        self.learning_rate= learning_rate\n",
    "        self.BCE = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.Classifier(x)\n",
    "        loss = self.BCE(x, y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.Classifier(x)\n",
    "        val_loss = self.BCE(x, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.Classifier(x)\n",
    "        test_loss = self.BCE(x, y)\n",
    "        self.log(\"test_loss\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file,index_col=0)\n",
    "        self.features = self.data.iloc[:,8:14].values  # Select all columns except the last one\n",
    "        self.labels = self.data.iloc[:,7].values  # Select the last column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.FloatTensor(self.features[idx])\n",
    "        label = torch.FloatTensor([self.labels[idx]])  # Assuming market direction is -1 or +1\n",
    "\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_dir: str = \"./EURUSD_train.csv\",test_dir: str = \"./EURUSD_test.csv\" , batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            markets_full = MarketDataset(self.train_dir)\n",
    "            total = len(markets_full)\n",
    "            train_val = round(total * 0.8)\n",
    "            lengths = [train_val, total - train_val]\n",
    "            self.markets_train, self.markets_val = random_split(\n",
    "                markets_full, lengths, generator=torch.Generator().manual_seed(42)\n",
    "            )\n",
    "\n",
    "        elif stage == 'test':\n",
    "            self.market_test = MarketDataset(self.test_dir)\n",
    "        # self.market_predict = MarketDataset(self.da_dir)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.markets_train, \n",
    "                        batch_size=self.batch_size,\n",
    "                        drop_last=True,\n",
    "                        shuffle=False,\n",
    "                    )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.markets_val, \n",
    "                        batch_size=self.batch_size,\n",
    "                        drop_last=True,\n",
    "                        shuffle=False,\n",
    "                    )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.markets_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.markets_predict, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ./checkpoints/lightning_logs\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | Classifier | Classifier        | 181   \n",
      "1 | BCE        | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "181       Trainable params\n",
      "0         Non-trainable params\n",
      "181       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edroberts/opt/anaconda3/envs/DNN_trading/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/edroberts/opt/anaconda3/envs/DNN_trading/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 100/100 [00:00<00:00, 165.26it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 100/100 [00:00<00:00, 163.78it/s, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "marketsDataset = MarketDataModule()\n",
    "model= LitClassifier(Classifier(5,1,10,10),learning_rate=1e-3)\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer(max_epochs=10,\n",
    "                    default_root_dir=\"./checkpoints/\")\n",
    "trainer.fit(model=model, train_dataloaders=marketsDataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
