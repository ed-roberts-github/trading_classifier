{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classifier\n",
    "\n",
    "In this notebook I explore building a neural netwrok classifier from lagged returns data. As with the SVM, this model is fundamentally flawed due to the efficient markets hypothesis, but again this provides good practice for building and backtesting models.\n",
    "\n",
    "I use PyTorch and Lightning here. This is obviously overkill for such a simple NN classifier however, it is once again a good learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightning as L\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_l1, hidden_l2):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l1, hidden_l2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l2, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitClassifier(L.LightningModule):\n",
    "    def __init__(self, Classifier, learning_rate):\n",
    "        super().__init__()\n",
    "        self.Classifier = Classifier\n",
    "        self.learning_rate= learning_rate\n",
    "        self.BCE = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.Classifier(x)\n",
    "        loss = self.BCE(x, y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"path/to/dir\", batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.mnist_test = MNIST(self.data_dir, train=False)\n",
    "        self.mnist_predict = MNIST(self.data_dir, train=False)\n",
    "        mnist_full = MNIST(self.data_dir, train=True)\n",
    "        self.mnist_train, self.mnist_val = random_split(\n",
    "            mnist_full, [55000, 5000], generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=self.batch_size)\n",
    "\n",
    "    def teardown(self, stage: str):\n",
    "        # Used to clean-up when the run is finished\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model= LitClassifier(Classifier(5,1,10,10))\n",
    "\n",
    "# train model\n",
    "trainer = L.Trainer()\n",
    "trainer.fit(model=model, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
