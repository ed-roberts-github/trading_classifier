{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Classifier\n",
    "\n",
    "In this notebook I explore building a neural netwrok classifier from lagged returns data. As with the SVM, this model is fundamentally flawed due to the efficient markets hypothesis, but again this provides good practice for building and backtesting models.\n",
    "\n",
    "I use PyTorch and Lightning here. This is obviously overkill for such a simple NN classifier however, it is once again a good learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from lightning.pytorch.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_l1, hidden_l2):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l1, hidden_l2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l1, hidden_l2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l1, hidden_l2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_l2, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitClassifier(L.LightningModule):\n",
    "    def __init__(self, Classifier, learning_rate):\n",
    "        super().__init__()\n",
    "        self.Classifier = Classifier\n",
    "        self.learning_rate= learning_rate\n",
    "        self.BCE = torch.nn.BCEWithLogitsLoss()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.Classifier(x)\n",
    "        loss = self.BCE(x, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.Classifier(x)\n",
    "        val_loss = self.BCE(x, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        x = self.Classifier(x)\n",
    "        test_loss = self.BCE(x, y)\n",
    "        self.log(\"test_loss\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x117f05e50>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 291d49fd0, raw_cell=\"df = pd.read_csv(\"EURUSD_train.csv\")\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/edroberts/Desktop/algo-trade/NN_model.ipynb#X20sZmlsZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x117f05e50>> (for post_run_cell), with arguments args (<ExecutionResult object at 28fef4990, execution_count=13 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 291d49fd0, raw_cell=\"df = pd.read_csv(\"EURUSD_train.csv\")\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/edroberts/Desktop/algo-trade/NN_model.ipynb#X20sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"EURUSD_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x117f05e50>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 28fee1690, raw_cell=\"df.iloc[:,8:14]\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/edroberts/Desktop/algo-trade/NN_model.ipynb#X21sZmlsZQ%3D%3D>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>returns_lag1</th>\n",
       "      <th>returns_lag2</th>\n",
       "      <th>returns_lag3</th>\n",
       "      <th>returns_lag4</th>\n",
       "      <th>returns_lag5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000515</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>-0.000421</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>-0.000421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>-0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>-0.000276</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      returns_lag1  returns_lag2  returns_lag3  returns_lag4  returns_lag5\n",
       "0        -0.000047     -0.000702     -0.000421      0.000327      0.000421\n",
       "1         0.000515     -0.000047     -0.000702     -0.000421      0.000327\n",
       "2         0.000515      0.000515     -0.000047     -0.000702     -0.000421\n",
       "3         0.000047      0.000515      0.000515     -0.000047     -0.000702\n",
       "4         0.000164      0.000047      0.000515      0.000515     -0.000047\n",
       "...            ...           ...           ...           ...           ...\n",
       "3995      0.000023      0.000046      0.000000     -0.000046      0.000138\n",
       "3996      0.000023      0.000023      0.000046      0.000000     -0.000046\n",
       "3997     -0.000276      0.000023      0.000023      0.000046      0.000000\n",
       "3998      0.000138     -0.000276      0.000023      0.000023      0.000046\n",
       "3999      0.000299      0.000138     -0.000276      0.000023      0.000023\n",
       "\n",
       "[4000 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x117f05e50>> (for post_run_cell), with arguments args (<ExecutionResult object at 120432590, execution_count=14 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 28fee1690, raw_cell=\"df.iloc[:,8:14]\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/edroberts/Desktop/algo-trade/NN_model.ipynb#X21sZmlsZQ%3D%3D> result=      returns_lag1  returns_lag2  returns_lag3  returns_lag4  returns_lag5\n",
      "0        -0.000047     -0.000702     -0.000421      0.000327      0.000421\n",
      "1         0.000515     -0.000047     -0.000702     -0.000421      0.000327\n",
      "2         0.000515      0.000515     -0.000047     -0.000702     -0.000421\n",
      "3         0.000047      0.000515      0.000515     -0.000047     -0.000702\n",
      "4         0.000164      0.000047      0.000515      0.000515     -0.000047\n",
      "...            ...           ...           ...           ...           ...\n",
      "3995      0.000023      0.000046      0.000000     -0.000046      0.000138\n",
      "3996      0.000023      0.000023      0.000046      0.000000     -0.000046\n",
      "3997     -0.000276      0.000023      0.000023      0.000046      0.000000\n",
      "3998      0.000138     -0.000276      0.000023      0.000023      0.000046\n",
      "3999      0.000299      0.000138     -0.000276      0.000023      0.000023\n",
      "\n",
      "[4000 rows x 5 columns]>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "df.iloc[:,8:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file,index_col=0)\n",
    "        self.features = self.data.iloc[:,8:14].values  # Select all columns except the last one\n",
    "        self.labels = self.data.iloc[:,7].values  # Select the last column\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.FloatTensor(self.features[idx])\n",
    "        label = torch.FloatTensor([self.labels[idx]])  # Assuming market direction is -1 or +1\n",
    "\n",
    "        return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarketDataModule(L.LightningDataModule):\n",
    "    def __init__(self, train_dir: str = \"./EURUSD_train.csv\",test_dir: str = \"./EURUSD_test.csv\" , batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        if stage == \"fit\":\n",
    "            markets_full = MarketDataset(self.train_dir)\n",
    "            total = len(markets_full)\n",
    "            train_val = round(total * 0.8)\n",
    "            lengths = [train_val, total - train_val]\n",
    "            self.markets_train, self.markets_val = random_split(\n",
    "                markets_full, lengths, generator=torch.Generator().manual_seed(42)\n",
    "            )\n",
    "\n",
    "        elif stage == 'test':\n",
    "            self.market_test = MarketDataset(self.test_dir)\n",
    "        # self.market_predict = MarketDataset(self.da_dir)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.markets_train, \n",
    "                        batch_size=self.batch_size,\n",
    "                        drop_last=True,\n",
    "                        shuffle=False,\n",
    "                    )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.markets_val, \n",
    "                        batch_size=self.batch_size,\n",
    "                        drop_last=True,\n",
    "                        shuffle=False,\n",
    "                    )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.markets_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.markets_predict, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edroberts/opt/anaconda3/envs/DNN_trading/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'Classifier' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['Classifier'])`.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33medroberts\u001b[0m (\u001b[33mjwst\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20231201_200702-g8miacn2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jwst/NN_trading/runs/g8miacn2' target=\"_blank\">warm-dream-7</a></strong> to <a href='https://wandb.ai/jwst/NN_trading' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jwst/NN_trading' target=\"_blank\">https://wandb.ai/jwst/NN_trading</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jwst/NN_trading/runs/g8miacn2' target=\"_blank\">https://wandb.ai/jwst/NN_trading/runs/g8miacn2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n",
      "/Users/edroberts/opt/anaconda3/envs/DNN_trading/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:43: attribute 'Classifier' removed from hparams because it cannot be pickled\n",
      "\n",
      "  | Name       | Type              | Params\n",
      "-------------------------------------------------\n",
      "0 | Classifier | Classifier        | 401   \n",
      "1 | BCE        | BCEWithLogitsLoss | 0     \n",
      "-------------------------------------------------\n",
      "401       Trainable params\n",
      "0         Non-trainable params\n",
      "401       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edroberts/opt/anaconda3/envs/DNN_trading/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/edroberts/opt/anaconda3/envs/DNN_trading/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 100/100 [00:00<00:00, 106.27it/s, v_num=acn2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 100/100 [00:01<00:00, 87.04it/s, v_num=acn2] \n",
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x117f05e50>> (for post_run_cell), with arguments args (<ExecutionResult object at 14f2b0410, execution_count=6 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 16c5967d0, raw_cell=\"marketsDataset = MarketDataModule()\n",
      "model= LitClas..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/edroberts/Desktop/algo-trade/NN_model.ipynb#W5sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "marketsDataset = MarketDataModule()\n",
    "model= LitClassifier(Classifier(5,1,10,10),learning_rate=1e-3)\n",
    "\n",
    "\n",
    "# train model\n",
    "wandb_logger = WandbLogger(project=\"NN_trading\", log_model=\"all\")\n",
    "trainer = L.Trainer(max_epochs=10,\n",
    "                    default_root_dir=\"./checkpoints/\",\n",
    "                    logger = wandb_logger)\n",
    "wandb_logger.watch(model)\n",
    "trainer.fit(model=model, train_dataloaders=marketsDataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
